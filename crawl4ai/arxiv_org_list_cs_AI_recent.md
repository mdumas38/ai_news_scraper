# Crawl Results for https://arxiv.org/list/cs.AI/recent

## Filtered Papers

### Mini-Omni: Language Models Can Hear, Talk While Thinking in Streaming

Authors: Zhifei Xie, Changqiao Wu
Date: 
Abstract: Abstract
Recent advances in language models have achieved significant progress. GPT-4o,
as a new milestone, has enabled real-time conversations with humans, demonstrat-
ing near-human natural fluency. Such human-computer interaction necessitates
models with the capability to perform reasoning directly with the audio modality
and generate output in streaming. However, this remains beyond the reach of
current academic models, as they typically depend on extra TTS systems for speech
synthesis, resulting in undesirable latency. This paper introduces the Mini-Omni ,
an audio-based end-to-end conversational model, capable of real-time speech inter-
action. To achieve this capability, we propose a text-instructed speech generation
method, along with batch-parallel strategies during inference to further boost the
performance. Our method also helps to retain the original model’s language ca-
pabilities with minimal degradation, enabling other works to establish real-time
interaction capabilities. We call this training method "Any Model Can Talk" . We
also introduce the VoiceAssistant-400K dataset to fine-tune models optimized for
speech output. To our best knowledge, Mini-Omni is the first fully end-to-end,
open-source model for real-time speech interaction, offering valuable potential for
future research.
Figure 1: The Mini-Omni model architecture introduces adapters to enhance audio capabilities,
enabling parallel generation of text-audio tokens. Additionally, the model employs streaming
decoding techniques to facilitate real-time interactions.
Technical report.arXiv:2408.16725v1  [cs.AI]  29 Aug 2024

### Guided Reasoning: A Non-Technical Introduction

Authors: Gregor Betz
Date: 
Abstract: Abstract. We introduce the concept and a default implementation of Guided Reasoning . A
multi-agent system is a Guided Reasoning system iff one agent (the guide) primarily interacts
with other agents in order to improve reasoning quality. We describe Logikon’s default
implementation of Guided Reasoning in non-technical terms. This is a living document we’ll
gradually enrich with more detailed information and examples.
Code: github.com/logikon-ai/logikon
Demo: huggingface.co/spaces/logikon/benjamin-chat

### Logic-Enhanced Language Model Agents for Trustworthy Social Simulations

Authors: Agnieszka Mensfelt, Kostas Stathis, Vince Trencsenyi
Date: 
Abstract: Abstract
We introduce the Logic-Enhanced Language Model Agents
(LELMA) framework, a novel approach to enhance the trust-
worthiness of social simulations that utilize large langua ge
models (LLMs). While LLMs have gained attention as agents
for simulating human behaviour, their applicability in thi s
role is limited by issues such as inherent hallucinations an d
logical inconsistencies. LELMA addresses these challenge s
by integrating LLMs with symbolic AI, enabling logical ver-
iﬁcation of the reasoning generated by LLMs. This veriﬁca-
tion process provides corrective feedback, reﬁning the rea -
soning output. The framework consists of three main compo-
nents: an LLM-Reasoner for producing strategic reasoning,
an LLM-Translator for mapping natural language reasoning
to logic queries, and a Solver for evaluating these queries.
This study focuses on decision-making in game-theoretic sc e-
narios as a model of human interaction. Experiments in-
volving the Hawk-Dove game, Prisoner’s Dilemma, and Stag
Hunt highlight the limitations of state-of-the-art LLMs, G PT-
4 Omni and Gemini

### SAM2Point: Segment Any 3D as Videos in Zero-shot and Promptable Manners

Authors: Ziyu Guo, Renrui Zhang, Xiangyang Zhu, Chengzhuo Tong, Peng Gao, Chunyuan Li, Pheng-Ann Heng
Date: 
Abstract: ABSTRACT We introduce SAM2POINT , a preliminary exploration adapting Segment Anything Model 2 (SAM 2) for zero-shot and promptable 3D segmentation. SAM2POINT interprets any 3D data as a series of multi-directional videos, and leverages SAM 2 for 3D-space segmentation, without further training or 2D-3D projection. Our framework supports various prompt types, including 3D points, boxes, and masks , and can generalize across diverse scenarios, such as 3D objects, indoor scenes, outdoor scenes, and raw LiDAR. Demonstrations on multiple 3D datasets, e.g., Objaverse, S3DIS, ScanNet, Semantic3D, and KITTI, highlight the robust general- ization capabilities of SAM2POINT . To our best knowledge, we present the most faithful implementation of SAM in 3D, which may serve as a starting point for future research in promptable 3D segmentation. Live Demo: https://huggingface.co/spaces/ZiyuG/SAM2Point Code: https://github.com/ZiyuGuo99/SAM2Point Indoor SceneOutdoor SceneRaw LiDAR3D PointPrompt3D BoxPrompt3D MaskPromptSAM2POINT 3D Object Figure 1: The Segmentation Paradigm of SAM2POINT .We introduce a zero-shot and promptable framework for robust 3D segmentation via SAM 2 (Ravi et al., 2024). It supports various user- provided 3D prompt, and can generalize to diverse 3D scenarios. The 3D prompt and segmentation results are highlighted in red and green, respectively. 1arXiv:2408.16768v1 [cs.CV] 29 Aug 2024Technical Report Table 1: Comparison of SAM2POINT and Previous SAM-based Methods (Yang et al., 2023b; Cen et al., 2023; Xu et al., 2023a; Zhou et al., 2024). To our best knowledge, SAM2POINT presents the most faithful implementation of SAM (Kirillov et al., 2023) in 3D, demonstrating superior implementation efficiency, promptable flexibility, and generalization capabilities for 3D segmentation. Method Zero-shot Project-free3D Prompt 3D Scenario Point Box Mask Object Indoor Outdoor Raw LiDAR SAM3D ✓ - - - - - ✓ - - SA3D ✓ - - - - - ✓ ✓ - SAMPro3D ✓ - - - - - ✓ - - Point-SAM - ✓ ✓ - - ✓ ✓ ✓ - SAM2POINT ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ ✓ 1 I NTRODUCTION Segment Anything Model (SAM) (Kirillov et al., 2023) has established a superior and fundamental framework for interactive image segmentation. Building on its strong transferability, follow-up research further extends SAM to diverse visual domains, e.g., personalized objects (Zhang et al., 2023b; Liu et al., 2023d), medical imaging (Ma et al., 2024; Mazurowski et al., 2023), and temporal sequences (Yang et al., 2023a; Cheng et al., 2023). More recently, Segment Anything Model 2 (SAM 2) (Ravi et al., 2024) is proposed for impressive segmentation capabilities in video scenarios, capturing complex real-world dynamics. Despite this, effectively adapting SAM for 3D segmentation still remains an unresolved challenge. We identify three primary issues within previous efforts, as compared in Table 1, which prevent them from fully leveraging SAM’s advantages: •Inefficient 2D-3D Projection. Considering the domain gap between 2D and 3D, most existing works represent 3D data as its 2D counterpart as input for SAM, and back-project the segmentation results into 3D space, e.g., using additional RGB images (Yang et al., 2023b; Yin et al., 2024; Xu et al., 2023a), multi-view renderings (Zhou et al., 2023b), or Neural...

### ReconX: Reconstruct Any Scene from Sparse Views with Video Diffusion Model

Authors: Fangfu Liu, Wenqiang Sun, Hanyang Wang, Yikai Wang, Haowen Sun, Junliang Ye, Jun Zhang, Yueqi Duan
Date: 
Abstract: ABSTRACT
Advancements in 3D scene reconstruction have transformed 2D images from the
real world into 3D models, producing realistic 3D results from hundreds of in-
put photos. Despite great success in dense-view reconstruction scenarios, ren-
dering a detailed scene from insufficient captured views is still an ill-posed op-
timization problem, often resulting in artifacts and distortions in unseen areas.
In this paper, we propose ReconX , a novel 3D scene reconstruction paradigm
that reframes the ambiguous reconstruction challenge as a temporal generation
task. The key insight is to unleash the strong generative prior of large pre-trained
video diffusion models for sparse-view reconstruction. However, 3D view con-
sistency struggles to be accurately preserved in directly generated video frames
from pre-trained models. To address this, given limited input views, the proposed
ReconX first constructs a global point cloud and encodes it into a contextual space
as the 3D structure condition. Guided by the condition, the video diffusion model
then synthesizes video frames that are both detail-preserved and exhibit a high
degree of 3D consistency, ensuring the coherence of the scene from various per-
spectives. Finally, we recover the 3D scene from the generated video through a
confidence-aware 3D Gaussian Splatting optimization scheme. Extensive exper-
iments on various real-world datasets show the superiority of our ReconX over
state-of-the-art methods in terms of quality and generalizability. Project Page:
https://liuff19.github.io/ReconX .
1 I NTRODUCTION
With the rapid development of photogrammetry techniques such as NeRF (Mildenhall et al., 2020)
and 3D Gaussian Splatting (3DGS) (Kerbl et al., 2023), 3D reconstruction has become a popular
research topic in recent years, finding various applications from virtual reality (Dalal et al., 2024)
to autonomous navigation (Adamkiewicz et al., 2022) and beyond (Martin-Brualla et al., 2021b;
Liu et al., 2024a; Wu et al., 2024a; Charatan et al., 2024). However, sparse-view reconstruction is
an ill-posed problem (Gao et al., 2024; Yu et al., 2021) since it involves recovering a complex 3D
structure from limited viewpoint information (

### A Score-Based Density Formula, with Applications in Diffusion Generative Models

Authors: Gen Li, Yuling Yan
Date: 
Abstract: Abstract
Score-based generative models (SGMs) have revolutionized the ﬁeld of generative modeling, achiev-
ing unprecedented success in generating realistic and dive rse content. Despite empirical advances, the
theoretical basis for why optimizing the evidence lower bou nd (ELBO) on the log-likelihood is eﬀective
for training diﬀusion generative models, such as DDPMs, rem ains largely unexplored. In this paper, we
address this question by establishing a density formula for a continuous-time diﬀusion process, which
can be viewed as the continuous-time limit of the forward pro cess in an SGM. This formula reveals the
connection between the target density and the score functio n associated with each step of the forward
process. Building on this, we demonstrate that the minimize r of the optimization objective for training
DDPMs nearly coincides with that of the true objective, prov iding a theoretical foundation for optimizing
DDPMs using the ELBO. Furthermore, we oﬀer new insights into the role of score-matching regular-
ization in training GANs, the use of ELBO in diﬀusion classiﬁ ers, and the recently proposed diﬀusion
loss.

### Dissecting Out-of-Distribution Detection and Open-Set Recognition: A Critical Analysis of Methods and Benchmarks

Authors: Hongjun Wang, Sagar Vaze, Kai Han
Date: 
Abstract: Abstract
Detecting test-time distribution shift has emerged as a key capability for safely deployed machine
learning models, with the question being tackled under various guises in recent years. In this paper,
we aim to provide a consolidated view of the two largest sub-fields within the community: out-of-
distribution (OOD) detection and open-set recognition (OSR). In particular, we aim to provide
rigorous empirical analysis of different methods across settings and provide actionable takeaways
for practitioners and researchers. Concretely, we make the following contributions: (i) We perform
rigorous cross-evaluation between state-of-the-art methods in the OOD detection and OSR settings
and identify a strong correlation between the performances of methods for them; (ii) We propose a
new, large-scale benchmark setting which we suggest better disentangles the problem tackled by OOD
detection and OSR, re-evaluating state-of-the-art OOD detection and OSR methods in this setting;
(iii) We surprisingly find that the best performing method on standard benchmarks (Outlier Exposure)
struggles when tested at scale, while scoring rules which are sensitive to the deep feature magnitude
consistently show promise; and (iv) We conduct empirical analysis to explain these phenomena and
highlight directions for future research. Code: https://github.com/Visual-AI/Dissect-OOD-OSR

### Assessing Large Language Models for Online Extremism Research: Identification, Explanation, and New Knowledge

Authors: Beidi Dong, Jin R. Lee, Ziwei Zhu, Balassubramanian Srinivasan
Date: 
Abstract: abstract  
evaluation metrics: The case o f hate speech detection. In Proceedings of the 2017 ACM 
on web science conference  (pp. 405 -406).  
 
Parekh, D., Amarasingam, A., Dawson, L., & Ruths, D. (2018). Studying jihadists on social  
media: A critique of data collection methodologies. Perspectives on Terrorism , 12(3), 5 -
23. 
 
Parkin, W. S., Freilich, J. D., & Chermak, S. M. (2015). Ideological victimization: Homicides  
perpetrated by far -right extremists. Homicide Studies , 19(3), 211 -236. 
 
Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen, T., Lin, Z.,  
Gimelshein, N., Antiga, L. and Desmaison, A.  (2019 ). Pytorch: An imperative style, 
high-performance deep learning library. Advances in neural information processing 
systems, 32.  
 
Patel, K., Agrahari, S., & Srivastava, S. (2020, June). Survey on fake p rofile detection on social  
sites by using machine learning algorithm. In 2020 8th international conference on 
reliability, infocom technologies and optimization (trends and future directions)(ICRITO)  
(pp. 1236 -1240). IEEE.  
 
Pauwels, L., & Schils, N. (2016 ). Differential online exposure to extremist content and political  
violence: Testing the relative strength of social learning and competing perspectives. 
Terrorism and Political Violence , 28(1), 1 -29. 
 
Perry, B., & Scrivens, R. (2016). Uneasy alliances: A  look at the right -wing extremist movement  
in Canada. Studies in Conflict & Terrorism , 39(9), 819 -84

### Smaller, Weaker, Yet Better: Training LLM Reasoners via Compute-Optimal Sampling

Authors: Hritik Bansal, Arian Hosseini, Rishabh Agarwal, Vinh Q. Tran, Mehran Kazemi
Date: 
Abstract: abstraction in large language models. arXiv preprint arXiv:2310.06117 , 2023. 17Smaller, Weaker, Yet Better: Training LLM Reasoners via Compute-Optimal Sampling A. Extending our results to coding tasks Low High Sampling budget5559636771757983879195coverage@cost (%)Coverage (MBPP) 27B 9B (compute-matched) (a) Coverage on MBPP. Low High Sampling budget0369121518# correct solutions per questionDiversity (MBPP) 27B 9B (compute-matched) (b) Diversity on MBPP. Figure 12|Synthetic data analysis for MBPP dataset. We present the (a) coverage, and (b) diversity for a subset of the santized MBPP dataset for Gemma2-27B and Gemma2-9B at two fixed sampling budgets. Low High Sampling Budget404346495255586164Pass@1 Accuracy (%)Student-LM Finetuning (MBPP->HumanEval) Ground-truth 27B 9B (compute-matched) (a) Finetuning Gemma-7B. Low High Sampling Budget52545658606264Pass@1 Accuracy (%)WC Finetuning (MBPP->HumanEval) Ground-truth 27B 9B (compute-matched) (b) Finetuning Gemma2-9B. Low High Sampling Budget56596265687174Pass@1 Accuracy (%)SE-LM Finetuning (MBPP->HumanEval) Ground-truth 27B 9B (compute-matched)(c) Finetuning Gemma2-27B. Figure 13|Supervised-finetuning with MBPP and evaluation on HumanEval. We report the results for finetuning diverse language models on the MBPP synthetic data from the SE model (Gemma2-9B) and WC model (Gemma2-27B) at the fixed sampling budgets. Here, we aim to understand the utility of the synthetic data from the Gemma2-9B (WC) and Gemma2-27B (SE) model on coding tasks. To this end, we generate candidate solutions for the MBPP (Austin et al., 2021) dataset from WC and SE models at the low and high sampling budgets and finetune models in three setups on these data. We use the santizied version of MBPP5containing 427 problems overall; we used 3problems for fewshot prompting (used for sampling from the models), 324problems for synthetic training data generation, and 100problems for validation. The candidate solutions are filtered by the unit tests that accompany each instance of the dataset. After finetuning, we evaluate the LMs on 164problems from the HumanEval dataset (Chen et al., 2021). We compare the coverage and diversity of the synthetic datasets in Figure 12 and observe that the coverage of the WC model is higher than SE at low data regime while it is similar to SE in the high sampling budget regime. In addition, we find that the diversity of the WC model is more than 5https://huggingface.co/datasets/google-research-datasets/mbpp/viewer/sanitized 18Smaller, Weaker, Yet Better: Training LLM Reasoners via Compute-Optimal Sampling that of the SE model for the low and high sampling budgets. Subsequently, we finetune Gemma-7B, Gemma2-9B, and Gemma2-27B models with the ground-truth and synthetic datasets and evaluate on HumanEval (Figure 13). Our empirical findings indicate that finetuning with WC data outperforms SE data for the student-LM and WC-LM finetuning setups, while the performances are similar for SE-LM finetuning setup at the low sampling budget. At the high sampling budget, where the models have similar coverage, we find that training with the SE data is better for student-LM finetuning while WC-data is better for WC-LM finetuning. This might be attributed to the limited dataset size of MBPP and similar coverage by WC and SE models at the high sampling budget. B. Qualitative Examples We present a few qualitative examples for model-generated solutions that lead to the correct final answer with incorrect (or correct)...

### A GREAT Architecture for Edge-Based Graph Problems Like TSP

Authors: Attila Lischka, Jiaming Wu, Morteza Haghir Chehreghani, Balázs Kulcsár
Date: 
Abstract: ABSTRACT In the last years, many neural network-based approaches have been proposed to tackle combinatorial optimization problems such as routing problems. Many of these approaches are based on graph neural networks (GNNs) or related trans- formers, operating on the Euclidean coordinates representing the routing prob- lems. However, GNNs are inherently not well suited to operate on dense graphs, such as in routing problems. Furthermore, models operating on Euclidean coor- dinates cannot be applied to non-Euclidean versions of routing problems that are often found in real-world settings. To overcome these limitations, we propose a novel GNN-related edge-based neural model called Graph Edge Attention Net- work (GREAT). We evaluate the performance of GREAT in the edge-classification task to predict optimal edges in the Traveling Salesman Problem (TSP). We can use such a trained GREAT model to produce sparse TSP graph instances, keep- ing only the edges GREAT finds promising. Compared to other, non-learning- based methods to sparsify TSP graphs, GREAT can produce very sparse graphs while keeping most of the optimal edges. Furthermore, we build a reinforce- ment learning-based GREAT framework which we apply to Euclidean and non- Euclidean asymmetric TSP. This framework achieves state-of-the-art results. 1 I NTRODUCTION Graph neural networks (GNNs) have emerged as a powerful tool for learning on graph-structured data such as molecules, social networks, or citation graphs Wu et al. (2020). In recent years, GNNs have also been applied in the setting of combinatorial optimization, especially routing problems Joshi et al. (2019); Hudson et al. (2021); Xin et al. (2021) since such problems can be interpreted as graph problems. However, the graph representations of routing problems, which are typically complete, dense graphs, are ill-suited for GNNs. This is because vanilla GNNs are not generally suitable for learning on complete graphs. GNNs are related to the Weisfeiler Leman algorithm which is known to exploit graph structure Morris et al. (2019). Complete graphs feature no such structure, resulting in poor GNN performance. Moreover, over-smoothing is a well-known problem happening in (deep) GNNs which means that feature vectors computed for different nodes become more and more similar with every layer Rusch et al. (2023). Naturally, in dense or even complete graphs this problem is even more present as all nodes share the same information leading to similar encodings. Consequently, Lischka et al. (2024) showed that the performance of GNNs operating on routing problems can be increased if graphs are made sparse in a preprocessing step. However, the proposed sparsification methods of Lischka et al. (2024) rely on hand-crafted heuristics which goes against the idea of data-driven, end-to-end machine learning frameworks. In this paper, we overcome the limitations of regular GNNs by introducing the Graph Edge Attention Network (GREAT). This results in the following contributions: • Whereas traditional GNNs operate on a node-level by using node-based message pass- ing operations, GREAT is edge-based, meaning information is passed along edges shar- ing endpoints. This makes GREAT perfect for edge-level tasks such as routing problems where the edges to travel along are selected....

### Entropic Distribution Matching in Supervised Fine-tuning of LLMs: Less Overfitting and Better Diversity

Authors: Ziniu Li, Congliang Chen, Tian Xu, Zeyu Qin, Jiancong Xiao, Ruoyu Sun, Zhi-Quan Luo
Date: 
Abstract: Abstract
Large language models rely on Supervised Fine-Tuning (SFT) to specialize in down-
stream tasks. Cross Entropy (CE) loss is the de facto choice in SFT, but it often leads
to overfitting and limited output diversity due to its aggressive updates to the data
distribution. This paper aim to address these issues by introducing the maximum entropy
principle, which favors models with flatter distributions that still effectively capture the
data. Specifically, we develop a new distribution matching method called GEM, which
solves reverse Kullback-Leibler divergence minimization with an entropy regularizer.
For the SFT of Llama-3-8B models, GEM outperforms CE in several aspects. First,
when applied to the UltraFeedback dataset to develop general instruction-following
abilities, GEM exhibits reduced overfitting, evidenced by lower perplexity and better
performance on the IFEval benchmark. Furthermore, GEM enhances output diversity,
leading to performance gains of up to 7 points on math reasoning and code generation
tasks using best-of-n sampling, even without domain-specific data. Second, when fine-
tuning with domain-specific datasets for math reasoning and code generation, GEM also
shows less overfitting and improvements of up to 10 points compared with CE.

### Jina-ColBERT-v2: A General-Purpose Multilingual Late Interaction Retriever

Authors: Rohan Jha, Bo Wang, Michael Günther, Saba Sturua, Mohammad Kalim Akram, Han Xiao
Date: 
Abstract: Abstract
Multi-vector dense models, such as ColBERT,
have proven highly effective in information re-
trieval. ColBERT’s late interaction scoring ap-
proximates the joint query-document attention
seen in cross-encoders while maintaining infer-
ence efficiency closer to traditional dense re-
trieval models, thanks to its bi-encoder architec-
ture and recent optimizations in indexing and
search. In this paper, we introduce several im-
provements to the ColBERT model architecture
and training pipeline, leveraging techniques
successful in the more established single-vector
embedding model paradigm, particularly those
suited for heterogeneous multilingual data. Our
new model, Jina-ColBERT-v2 , demonstrates
strong performance across a range of English
and multilingual retrieval tasks, while also cut-
ting storage requirements by up to 50% com-
pared to previous models.

### Iterative Graph Alignment

Authors: Fangyuan Yu, Hardeep Singh Arora, Matt Johnson
Date: 
Abstract: Abstract
By compressing diverse narratives, LLMs go beyond memorization, achieving
intelligence by capturing generalizable causal relationships. However, they suffer
from local ’representation gaps’ due to insufficient training data diversity, limiting
their real-world utility, especially in tasks requiring strict alignment to rules. Tradi-
tional alignment methods relying on heavy human annotations are inefficient and
unscalable. Recent self-alignment techniques also fall short, as they often depend
on self-selection based prompting and memorization-based learning. To address
these issues, we introduce Iterative Graph Alignment (IGA), an annotation-free
rule-based alignment algorithm. A teacher model (VLM) employs Iterative Graph
Prompting (IGP) to create logical graphs and reference answers. The student model
(LLM) identifies local knowledge gaps by attempting to align its responses with
these references, collaborating with helper models to generate diverse answers.
These aligned responses are then used for iterative supervised fine-tuning (SFT).
Our evaluations across five rule-based scenarios demonstrate IGP’s effectiveness,
with a 73.12% alignment improvement in Claude Sonnet 3.5, and Llama3-8B-
Instruct achieving an 86.20% improvement, outperforming Claude Sonnet 3.5 in
rule-based alignment.

### DriveGenVLM: Real-world Video Generation for Vision Language Model based Autonomous Driving

Authors: Yongjie Fu, Anmol Jain, Xuan Di, Xu Chen, Zhaobin Mo
Date: 
Abstract: Abstract — The advancement of autonomous driving tech-
nologies necessitates increasingly sophisticated methods for
understanding and predicting real-world scenarios. Vision lan-
guage models (VLMs) are emerging as revolutionary tools with
significant potential to influence autonomous driving. In this
paper, we propose the DriveGenVLM framework to generate
driving videos and use VLMs to understand them. To achieve
this, we employ a video generation framework grounded in
denoising diffusion probabilistic models (DDPM) aimed at
predicting real-world video sequences. We then explore the
adequacy of our generated videos for use in VLMs by employing
a pre-trained model known as Efficient In-context Learning on
Egocentric Videos (EILEV). The diffusion model is trained with
the Waymo open dataset and evaluated using the Fr ´echet Video
Distance (FVD) score to ensure the quality and realism of the
generated videos. Corresponding narrations are provided by
EILEV for these generated videos, which may be beneficial in
the autonomous driving domain. These narrations can enhance
traffic scene understanding, aid in navigation, and improve
planning capabilities. The integration of video generation with
VLMs in the DriveGenVLM framework represents a significant
step forward in leveraging advanced AI models to address
complex challenges in autonomous driving.

### RLCP: A Reinforcement Learning-based Copyright Protection Method for Text-to-Image Diffusion Model

Authors: Zhuan Shi, Jing Yan, Xiaoli Tang, Lingjuan Lyu, Boi Faltings
Date: 
Abstract: Abstract
The increasing sophistication of text-to-image generative
models has led to complex challenges in defining and en-
forcing copyright infringement criteria and protection. Ex-
isting methods, such as watermarking and dataset dedupli-
cation, fail to provide comprehensive solutions due to the
lack of standardized metrics and the inherent complexity
of addressing copyright infringement in diffusion models.
To deal with these challenges, we propose a R einforcement
Learning-based C opyright P rotection( RLCP ) method for
Text-to-Image Diffusion Model, which minimizes the gener-
ation of copyright-infringing content while maintaining the
quality of the model-generated dataset. Our approach begins
with the

### Optimizing Automated Picking Systems in Warehouse Robots Using Machine Learning

Authors: Keqin Li, Jin Wang, Xubo Wu, Xirui Peng, Runmian Chang, Xiaoyu Deng, Yiwen Kang, Yue Yang, Fanghao Ni, Bo Hong
Date: 
Abstract: Abstract—With the rapid growth of global e -commerce, the 
demand for automation in the logistics industry is increasing. This 
study focuses on automated picking systems in warehouses, 
utilizing deep learning and reinforcement learning technologies to 
enhance picking  efficiency and accuracy while reducing system 
failure rates. Through empirical analysis, we demonstrate the 
effectiveness of these technologies in improving robot picking 
performance and adaptability to complex environments. The 
results show that the inte grated machine learning model 
significantly outperforms traditional methods, effectively 
addressing the challenges of peak order processing, reducing 
operational errors, and improving overall logistics efficiency. 
Additionally, by analyzing environmental f actors, this study 
further optimizes system design to ensure efficient and stable operation under variable conditions. This research not only provides innovative solutions for logistics automation but also 
offers a theoretical and empirical foundation for future 
technological development and application. (Abstract)

### Maelstrom Networks

Authors: Matthew Evanusa, Cornelia Fermüller, Yiannis Aloimonos
Date: 
Abstract: ABSTRACT Artificial Neural Networks has struggled to devise a way to incorporate working memory into neural networks. While the “long term” memory can be seen as the learned weights, the working memory consists likely more of dynamical activity, that is missing from feed-forward models. This leads to a weakness in current neu- ral network models: they cannot actually process temporal data in time, without access to some kind of working memory. Current state of the art models such as transformers tend to “solve” this by ignoring working memory entirely and simply process the sequence as an entire piece of data; however this means the network cannot process the sequence in an online fashion, and leads to an immense explo- sion in memory requirements. In the decades prior, a separate track of research has followed recurrent neural networks that maintain a working memory via a dy- namic state, although training these weights has proven difficult. Here, inspired by a combination of controls, reservoir computing, deep learning, and recurrent neural networks, we offer an alternative paradigm that combines the strength of recurrent networks, with the pattern matching capability of feed-forward neural networks, which we call the Maelstrom Networks paradigm. This paradigm leaves the recurrent component - the Maelstrom - unlearned, and offloads the learning to a powerful feed-forward network. This allows the network to leverage the strength of feed-forward training without unrolling the network, and allows for the memory to be implemented in new neuromorphic hardware. It endows a neural network with a sequential memory that takes advantage of the inductive bias that data is organized causally in the temporal domain, and imbues the network with a state that represents the agent’s “self”, moving through the environment. This could also lead the way to continual learning, with the network modularized and “’pro- tected” from overwrites that come with new data. In addition to aiding in solving these performance problems that plague current non-temporal deep networks, this also could finally lead towards endowing artificial networks with a sense of “self”. 1 I NTRODUCTION The ultimate goal of artificial intelligence is to recreate the intelligence that biological agents have displayed to remarkable degree, extract the core components of intelligence, and reproduce this in an artificial agent, potentially amplifying this. Since the early days of connectionist networks, where we attempt to solve this intelligence problem through networks (or graphs) of simple artifi- cial neural units, the goal has somewhat drifted away from a general artificial agent towards more specialized tasks, namely, pattern recognition. Feed-forward neural networks, built off of the Per- ceptron framework (Rosenblatt, 1961), have excelled at pattern recognition, and have reoriented the entire field towards this mapping function. This has culimated in the current generation of Large Language Models, which are at the core, meta-networks of Perceptrons trained using backpropaga- tion (Vaswani et al., 2017). What have we sacrificed in this focus on pattern recognition? This is the Distribution Statement A. Approved for public release: distribution is unlimited. 1arXiv:2408.16632v1 [cs.NE] 29 Aug 2024question...

### LLMs generate structurally realistic social networks but overestimate political homophily

Authors: Serina Chang, Alicja Chaszczewicz, Emma Wang, Maya Josifovska, Emma Pierson, Jure Leskovec
Date: 
Abstract: Abstract
Generating social networks is essential for
many applications, such as epidemic model-
ing and social simulations. Prior approaches
either involve deep learning models, which re-
quire many observed networks for training, or
stylized models, which are limited in their re-
alism and flexibility. In contrast, LLMs of-
fer the potential for zero-shot and flexible net-
work generation. However, two key questions
are: (1) are LLM’s generated networks realis-
tic, and (2) what are risks of bias, given the
importance of demographics in forming social
ties? To answer these questions, we develop
three prompting methods for network gener-
ation and compare the generated networks to
real social networks. We find that more realis-
tic networks are generated with “local” meth-
ods, where the LLM constructs relations for
one persona at a time, compared to “global”
methods that construct the entire network at
once. We also find that the generated networks
match real networks on many characteristics,
including density, clustering, community struc-
ture, and degree. However, we find that LLMs
emphasize political homophily over all other
types of homophily and overestimate political
homophily relative to real-world measures.

### Towards Infusing Auxiliary Knowledge for Distracted Driver Detection

Authors: Ishwar B Balappanawar, Ashmit Chamoli, Ruwan Wickramarachchi, Aditya Mishra, Ponnurangam Kumaraguru, Amit P. Sheth
Date: 
Abstract: Abstract
Distracted driving is a leading cause of road accidents globally. Identification of distracted driving involves reliably detecting
and classifying various forms of driver distraction (e.g., texting, eating, or using in-car devices) from in-vehicle camera feeds
to enhance road safety. This task is challenging due to the need for robust models that can generalize to a diverse set of driver
behaviors without requiring extensive annotated datasets. In this paper, we propose KiD3 , a novel method for distracted
driver detection (DDD) by infusing auxiliary knowledge about semantic relations between entities in a scene and the structural
configuration of the driver’s pose. Specifically, we construct a unified framework that integrates the scene graphs, and driver’s
pose information with the visual cues in video frames to create a holistic representation of the driver’s actions. Our results
indicate that KiD3 achieves a 13.64% accuracy improvement over the vision-only baseline by incorporating such auxiliary
knowledge with visual information. The source code for KiD3 is available at: https://github.com/ishwarbb/KiD3.

### Hyperdimensional Vector Tsetlin Machines with Applications to Sequence Learning and Generation

Authors: Christian D. Blakely
Date: 
Abstract: ABSTRACT
We construct a two-layered model for learning and generating sequential data that is both computa-
tionally fast and competitive with vanilla Tsetlin machines, adding numerous advantages. Through
the use of hyperdimensional vector computing (HVC) algebras and Tsetlin machine clause structures,
we demonstrate that the combination of both inherits the generality of data encoding and decoding
of HVC with the fast interpretable nature of Tsetlin machines to yield a powerful machine learning
model. We apply the approach in two areas, namely in forecasting, generating new sequences, and
classification. For the latter, we derive results for the entire UCR Time Series Archive and compare
with the standard benchmarks to see how well the method competes in time series classification.

### Examination of Code generated by Large Language Models

Authors: Robin Beer, Alexander Feix, Tim Guttzeit, Tamara Muras, Vincent Müller, Maurice Rauscher, Florian Schäffler, Welf Löwe
Date: 
Abstract: abstraction level in programming, to the end of programming as a profession,
substitute by prompts that describe what software is supposed to do instead of how.
This raises several questions: How advanced are LLMs today,

### Enhancing Dialogue Generation in Werewolf Game Through Situation Analysis and Persuasion Strategies

Authors: Zhiyang Qi, Michimasa Inaba
Date: 
Abstract: Abstract
Recent advancements in natural language pro-
cessing, particularly with large language mod-
els (LLMs) like GPT-4, have significantly en-
hanced dialogue systems, enabling them to gen-
erate more natural and fluent conversations.
Despite these improvements, challenges per-
sist, such as managing continuous dialogues,
memory retention, and minimizing hallucina-
tions. The AIWolfDial2024 addresses these
challenges by employing the Werewolf Game,
an incomplete information game, to test the
capabilities of LLMs in complex interactive
environments. This paper introduces a LLM-
based Werewolf Game AI, where each role is
supported by situation analysis to aid response
generation. Additionally, for the werewolf role,
various persuasion strategies, including logi-
cal appeal, credibility appeal, and emotional
appeal, are employed to effectively persuade
other players to align with its actions.

### Seeking the Sufficiency and Necessity Causal Features in Multimodal Representation Learning

Authors: Boyu Chen, Junjie Liu, Zhu Li, Mengyue yang
Date: 
Abstract: Abstract
Learning representations with a high Probability of Neces-
sary and Sufficient Causes (PNS) has been shown to enhance
deep learning models’ ability. This task involves identify-
ing causal features that are both sufficient (guaranteeing the
outcome) and necessary (without which the outcome cannot
occur). However, current research predominantly focuses on
unimodal data, and extending PNS learning to multimodal
settings presents significant challenges. The challenges arise
as the conditions for PNS identifiability—Exogeneity and
Monotonicity—need to be reconsidered in a multimodal
context, where sufficient and necessary causal features are
distributed across different modalities. To address this, we
first propose conceptualizing multimodal representations as
comprising modality-invariant and modality-specific compo-
nents. We then analyze PNS identifiability for each compo-
nent, while ensuring non-trivial PNS estimation. Finally, we
formulate tractable optimization objectives that enable mul-
timodal models to learn high-PNS representations, thereby
enhancing their predictive performance. Experiments demon-
strate the effectiveness of our method on both synthetic and
real-world data.

### SFR-GNN: Simple and Fast Robust GNNs against Structural Attacks

Authors: Xing Ai, Guanyu Zhu, Yulin Zhu, Yu Zheng, Gaolei Li, Jianhua Li, Kai Zhou
Date: 
Abstract: Abstract
Graph Neural Networks (GNNs) have demonstrated com-
mendable performance for graph-structured data. Yet, GNNs
are often vulnerable to adversarial structural attacks as em-
bedding generation relies on graph topology. Existing efforts
are dedicated to purifying the maliciously modified structure
or applying adaptive aggregation, thereby enhancing the ro-
bustness against adversarial structural attacks. It is inevitable
for a defender to consume heavy computational costs due to
lacking prior knowledge about modified structures. To this
end, we propose an efficient defense method, called S imple
and F ast R obust G raph N eural N etwork (SFR-GNN), sup-
ported by mutual information theory. The SFR-GNN first pre-
trains a GNN model using node attributes and then fine-tunes
it over the modified graph in the manner of contrastive learn-
ing, which is free of purifying modified structures and adap-
tive aggregation, thus achieving great efficiency gains. Conse-
quently, SFR-GNN exhibits a 24%–162% speedup compared
to advanced robust models, demonstrating superior robust-
ness for node classification tasks.

### Adaptive Variational Continual Learning via Task-Heuristic Modelling

Authors: Fan Yang
Date: 
Abstract: Abstract
Variational continual learning (VCL) is a turn-key learning algorithm that has state-
of-the-art performance among the best continual learning models. In our work,
we explore an extension of the generalized variational continual learning (GVCL)
model, named AutoVCL, which combines task heuristics for informed learning
and model optimization. We demonstrate that our model outperforms the standard
GVCL with fixed hyperparameters, benefiting from the automatic adjustment of
the hyperparameter based on the difficulty and similarity of the incoming task
compared to the previous tasks.

